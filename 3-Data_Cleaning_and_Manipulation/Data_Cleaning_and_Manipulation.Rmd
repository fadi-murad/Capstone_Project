---
title: "Data Cleaning and Manipulation"
author: "Fadi Murad"
date: "June 20, 2018"
output:
  html_document:
    theme: cerulean
    toc: true
    toc_depth: 4 
    toc_float: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE ,message=FALSE,comment="")
```

### 1- Missing Values

First let us split the data sets to numeric and categorical, it's easier for this step

*Note: I saved the training and test sets from the data exploration step as RData files to be able to use it in this R MarkDown file
*
```{r }

library(caret)
library(mlr)

load(file="tr.RData")
load(file="test.RData")

catcol <- c(2:5,7,8:16,20:29,31:38,40)
numcol <- c(setdiff(1:40,catcol),41)

tr_num <- tr[numcol]
tr_cat <- tr[catcol]

test_num <- test[numcol]
test_cat <- test[catcol]
```


<br />  


Let’s check for missing values in numeric variables, We’ll use sapply() to find out percentage of missing values per each variable.

```{r}
trNumMissing <- sapply(tr_num, function(x){sum(is.na(x))/length(x)})
testNumMissing <- sapply(test_num, function(x){sum(is.na(x)/length(x))})

trNumMissing
testNumMissing
```

There is no missing values in the numerical variables.Anyhow, let us turn our focus now to the missing values in the categorical variables, 

```{r}
trCatMissing <- sapply(tr_cat, function(x){sum(is.na(x))/length(x)})
testCatMissing <- sapply(test_cat, function(x){sum(is.na(x)/length(x))})

trCatMissing
testCatMissing
```

 
There are 9 variables have missing values 3 of them have almost 50% missing values.
We will dorp off variables with more than 10% missing values from our set


```{r}
tr_cat <- subset(tr_cat, select = trCatMissing < 0.1 )
test_cat <- subset(test_cat, select = trCatMissing < 0.1)

```

###2. Near Zero Variance Variables
During the exploration setp we saw alot of variables have one level with very high frequency
(around 90% of the data belong to one level) while the other levels have very low 
frequency ( between 1% to 4%), usually this kind of variables doesn't have much information
to offer to the predictive models, we will use nearZeroVar function to locate those variables  

**nearZeroVar** diagnoses predictors that have one unique value or predictors that are have 
both of the following characteristics: They have very few unique values relative to the 
number of samples and the ratio of the frequency of the most common value to the frequency of the second most common value is large.

####2.1 Numeric Variable

```{r}
nzvNum <- nearZeroVar(tr_num, saveMetrics= TRUE)
subset(nzvNum, nzvNum$nzv == TRUE)
```

As we saw on the exploration step those variables have a huge amount of Zero values, we will reclassify those variable to categorical with only 2 levels "zero" & "more than zero" 

```{r}
tr_num$wage_per_hour <- as.factor(ifelse(tr_num$wage_per_hour == 0,"Zero","MoreThanZero"))
tr_num$capital_gains <- as.factor(ifelse(tr_num$capital_gains == 0,"Zero","MoreThanZero"))
tr_num$capital_losses <- as.factor(ifelse(tr_num$capital_losses == 0,"Zero","MoreThanZero"))
tr_num$dividend_from_Stocks <- as.factor(ifelse(tr_num$dividend_from_Stocks == 0,"Zero","MoreThanZero"))

test_num$wage_per_hour <- as.factor(ifelse(test_num$wage_per_hour == 0,"Zero","MoreThanZero"))
test_num$capital_gains <- as.factor(ifelse(test_num$capital_gains == 0,"Zero","MoreThanZero"))
test_num$capital_losses <- as.factor(ifelse(test_num$capital_losses == 0,"Zero","MoreThanZero"))
test_num$dividend_from_Stocks <- as.factor(ifelse(test_num$dividend_from_Stocks == 0,"Zero","MoreThanZero"))

```



<br />  

####2.2 Categorical Variables

We will drop all the variable where **nearZeroVar** is true

```{r}
nzvCat <- nearZeroVar(tr_cat,freqCut = 90/10, saveMetrics= TRUE)
subset(nzvCat, nzvCat$nzv == TRUE)


tr_cat[nzvCat$nzv == TRUE] <- NULL
test_cat[nzvCat$nzv == TRUE] <- NULL
```


<br />  


###3. Checking Levels train/test
When applying our classification model error could appear when we have level in test set that doesn't exist in the train set  

Therefore we will check level count for each categorical variable in train and test sets
```{r}
summarizeColumns(tr_cat)[,"nlevs"]
summarizeColumns(test_cat)[,"nlevs"]
```

Only d_household_family_stat variable have one additonal level in the train set and this shouldn't be a problem  

However this variable has levels with very low frequency 6, 9, 37 ...., this will affect cross validation process for specific models later on, therefore and only for this variable, we will combain all the levels with less than 1% frequency to new level "others"

```{r}
#levels with less than 1% frequency
which(prop.table(table(tr_cat$d_household_family_stat)) < 0.01)

#Changing Levels
tr_d_hous <- names(which(prop.table(table(tr_cat$d_household_family_stat)) < 0.01))
test_d_hous <-names(which(prop.table(table(test_cat$d_household_family_stat)) < 0.01))

levels(tr_cat$d_household_family_stat) [levels(tr_cat$d_household_family_stat) %in% tr_d_hous] <- "others"
levels(test_cat$d_household_family_stat) [levels(test_cat$d_household_family_stat) %in% test_d_hous] <- "others"

```


Finally, we will combine the numeric and categorical subsets to train and test sets, remove the subsets, change the class of income level to factor, and check the result

```{r results="hide"}
f_tr <- cbind(tr_num,tr_cat)
f_test <- cbind(test_num,test_cat)

remove(tr_cat,test_cat,tr_num,test_num)

f_tr$income_level <- as.factor(f_tr$income_level)
f_test$income_level <- as.factor(f_test$income_level)

str(f_tr)
str(f_test)

```
  
<br />
*Now we have 23 variables (including the target variable) ready to be used in the machine learning step
*